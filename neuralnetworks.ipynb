{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c68aa9-eed7-42c6-b9a8-49df2e0d9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c2f9394-2aad-41d9-bdff-86f8ea7e222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9960ec10-2178-469a-a2e4-10340d9134aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aababb9-9db9-467f-bec8-0763d659f4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_sequence</th>\n",
       "      <th>feat_A</th>\n",
       "      <th>feat_C</th>\n",
       "      <th>feat_D</th>\n",
       "      <th>feat_E</th>\n",
       "      <th>feat_F</th>\n",
       "      <th>feat_G</th>\n",
       "      <th>feat_H</th>\n",
       "      <th>feat_I</th>\n",
       "      <th>feat_K</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_DSSP_10</th>\n",
       "      <th>feat_DSSP_11</th>\n",
       "      <th>feat_DSSP_12</th>\n",
       "      <th>feat_DSSP_13</th>\n",
       "      <th>coord_X</th>\n",
       "      <th>coord_Y</th>\n",
       "      <th>coord_Z</th>\n",
       "      <th>entry</th>\n",
       "      <th>entry_index</th>\n",
       "      <th>y_Ligand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-26.499001</td>\n",
       "      <td>-4.742</td>\n",
       "      <td>-35.189999</td>\n",
       "      <td>GEMI5_HUMAN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.158001</td>\n",
       "      <td>-1.342</td>\n",
       "      <td>-34.104000</td>\n",
       "      <td>GEMI5_HUMAN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-21.926001</td>\n",
       "      <td>-1.641</td>\n",
       "      <td>-32.175999</td>\n",
       "      <td>GEMI5_HUMAN</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>706</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>705</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-22.073999</td>\n",
       "      <td>0.654</td>\n",
       "      <td>-29.171000</td>\n",
       "      <td>GEMI5_HUMAN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>705</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-19.783001</td>\n",
       "      <td>2.670</td>\n",
       "      <td>-26.858999</td>\n",
       "      <td>GEMI5_HUMAN</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  annotation_sequence  feat_A  feat_C  feat_D  feat_E  feat_F  feat_G  feat_H  \\\n",
       "0                   M   False   False   False   False   False   False   False   \n",
       "1                   G   False   False   False   False   False    True   False   \n",
       "2                   Q   False   False   False   False   False   False   False   \n",
       "3                   E   False   False   False    True   False   False   False   \n",
       "4                   P   False   False   False   False   False   False   False   \n",
       "\n",
       "   feat_I  feat_K  ...  feat_DSSP_10  feat_DSSP_11  feat_DSSP_12  \\\n",
       "0   False   False  ...             0           0.0            47   \n",
       "1   False   False  ...             0           0.0             0   \n",
       "2   False   False  ...             1          -0.0            -1   \n",
       "3   False   False  ...           706          -0.1           705   \n",
       "4   False   False  ...             0           0.0           705   \n",
       "\n",
       "   feat_DSSP_13    coord_X  coord_Y    coord_Z        entry  entry_index  \\\n",
       "0          -0.0 -26.499001   -4.742 -35.189999  GEMI5_HUMAN            0   \n",
       "1           0.0 -25.158001   -1.342 -34.104000  GEMI5_HUMAN            1   \n",
       "2          -0.0 -21.926001   -1.641 -32.175999  GEMI5_HUMAN            2   \n",
       "3          -0.0 -22.073999    0.654 -29.171000  GEMI5_HUMAN            3   \n",
       "4          -0.2 -19.783001    2.670 -26.858999  GEMI5_HUMAN            4   \n",
       "\n",
       "   y_Ligand  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"af2_dataset_training_labeled.csv.gz\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3293764a-2c64-4481-9370-38629795d762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 497166 entries, 0 to 759\n",
      "Data columns (total 50 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   annotation_sequence  497166 non-null  object \n",
      " 1   feat_A               497166 non-null  bool   \n",
      " 2   feat_C               497166 non-null  bool   \n",
      " 3   feat_D               497166 non-null  bool   \n",
      " 4   feat_E               497166 non-null  bool   \n",
      " 5   feat_F               497166 non-null  bool   \n",
      " 6   feat_G               497166 non-null  bool   \n",
      " 7   feat_H               497166 non-null  bool   \n",
      " 8   feat_I               497166 non-null  bool   \n",
      " 9   feat_K               497166 non-null  bool   \n",
      " 10  feat_L               497166 non-null  bool   \n",
      " 11  feat_M               497166 non-null  bool   \n",
      " 12  feat_N               497166 non-null  bool   \n",
      " 13  feat_P               497166 non-null  bool   \n",
      " 14  feat_Q               497166 non-null  bool   \n",
      " 15  feat_R               497166 non-null  bool   \n",
      " 16  feat_S               497166 non-null  bool   \n",
      " 17  feat_T               497166 non-null  bool   \n",
      " 18  feat_V               497166 non-null  bool   \n",
      " 19  feat_W               497166 non-null  bool   \n",
      " 20  feat_Y               497166 non-null  bool   \n",
      " 21  annotation_atomrec   484477 non-null  object \n",
      " 22  feat_PHI             497166 non-null  float64\n",
      " 23  feat_PSI             497166 non-null  float64\n",
      " 24  feat_TAU             497166 non-null  float64\n",
      " 25  feat_THETA           497166 non-null  float64\n",
      " 26  feat_BBSASA          497166 non-null  float64\n",
      " 27  feat_SCSASA          497166 non-null  float64\n",
      " 28  feat_pLDDT           497166 non-null  float64\n",
      " 29  feat_DSSP_H          497166 non-null  bool   \n",
      " 30  feat_DSSP_B          497166 non-null  bool   \n",
      " 31  feat_DSSP_E          497166 non-null  bool   \n",
      " 32  feat_DSSP_G          497166 non-null  bool   \n",
      " 33  feat_DSSP_I          497166 non-null  bool   \n",
      " 34  feat_DSSP_T          497166 non-null  bool   \n",
      " 35  feat_DSSP_S          497166 non-null  bool   \n",
      " 36  feat_DSSP_6          497166 non-null  int64  \n",
      " 37  feat_DSSP_7          497166 non-null  float64\n",
      " 38  feat_DSSP_8          497166 non-null  int64  \n",
      " 39  feat_DSSP_9          497166 non-null  float64\n",
      " 40  feat_DSSP_10         497166 non-null  int64  \n",
      " 41  feat_DSSP_11         497166 non-null  float64\n",
      " 42  feat_DSSP_12         497166 non-null  int64  \n",
      " 43  feat_DSSP_13         497166 non-null  float64\n",
      " 44  coord_X              497166 non-null  float64\n",
      " 45  coord_Y              497166 non-null  float64\n",
      " 46  coord_Z              497166 non-null  float64\n",
      " 47  entry                497166 non-null  object \n",
      " 48  entry_index          497166 non-null  int64  \n",
      " 49  y_Ligand             497166 non-null  bool   \n",
      "dtypes: bool(28), float64(14), int64(5), object(3)\n",
      "memory usage: 100.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# find any missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1823b08-b3f1-46da-940a-5e59443c529c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = df['y_Ligand'].value_counts() / len(df)\n",
    "counts.plot.bar()\n",
    "plt.title('Percentage of binding and non-binding residue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c70e1b0d-2c7a-49c1-84b3-1bd435bd8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"y_Ligand\"].astype(int)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "975af3b6-db70-4f0f-9e3f-24cd29a80512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 497166 entries, 0 to 759\n",
      "Data columns (total 46 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   feat_A        497166 non-null  int32  \n",
      " 1   feat_C        497166 non-null  int32  \n",
      " 2   feat_D        497166 non-null  int32  \n",
      " 3   feat_E        497166 non-null  int32  \n",
      " 4   feat_F        497166 non-null  int32  \n",
      " 5   feat_G        497166 non-null  int32  \n",
      " 6   feat_H        497166 non-null  int32  \n",
      " 7   feat_I        497166 non-null  int32  \n",
      " 8   feat_K        497166 non-null  int32  \n",
      " 9   feat_L        497166 non-null  int32  \n",
      " 10  feat_M        497166 non-null  int32  \n",
      " 11  feat_N        497166 non-null  int32  \n",
      " 12  feat_P        497166 non-null  int32  \n",
      " 13  feat_Q        497166 non-null  int32  \n",
      " 14  feat_R        497166 non-null  int32  \n",
      " 15  feat_S        497166 non-null  int32  \n",
      " 16  feat_T        497166 non-null  int32  \n",
      " 17  feat_V        497166 non-null  int32  \n",
      " 18  feat_W        497166 non-null  int32  \n",
      " 19  feat_Y        497166 non-null  int32  \n",
      " 20  feat_PHI      497166 non-null  float64\n",
      " 21  feat_PSI      497166 non-null  float64\n",
      " 22  feat_TAU      497166 non-null  float64\n",
      " 23  feat_THETA    497166 non-null  float64\n",
      " 24  feat_BBSASA   497166 non-null  float64\n",
      " 25  feat_SCSASA   497166 non-null  float64\n",
      " 26  feat_pLDDT    497166 non-null  float64\n",
      " 27  feat_DSSP_H   497166 non-null  int32  \n",
      " 28  feat_DSSP_B   497166 non-null  int32  \n",
      " 29  feat_DSSP_E   497166 non-null  int32  \n",
      " 30  feat_DSSP_G   497166 non-null  int32  \n",
      " 31  feat_DSSP_I   497166 non-null  int32  \n",
      " 32  feat_DSSP_T   497166 non-null  int32  \n",
      " 33  feat_DSSP_S   497166 non-null  int32  \n",
      " 34  feat_DSSP_6   497166 non-null  int64  \n",
      " 35  feat_DSSP_7   497166 non-null  float64\n",
      " 36  feat_DSSP_8   497166 non-null  int64  \n",
      " 37  feat_DSSP_9   497166 non-null  float64\n",
      " 38  feat_DSSP_10  497166 non-null  int64  \n",
      " 39  feat_DSSP_11  497166 non-null  float64\n",
      " 40  feat_DSSP_12  497166 non-null  int64  \n",
      " 41  feat_DSSP_13  497166 non-null  float64\n",
      " 42  coord_X       497166 non-null  float64\n",
      " 43  coord_Y       497166 non-null  float64\n",
      " 44  coord_Z       497166 non-null  float64\n",
      " 45  entry_index   497166 non-null  int64  \n",
      "dtypes: float64(14), int32(27), int64(5)\n",
      "memory usage: 127.1 MB\n"
     ]
    }
   ],
   "source": [
    "# dropping columns\n",
    "# - annotation_sequence: covered by feat_[letter]\n",
    "# - annotation_atomrec: don't know what exactly it is (almost same as annotation_sequence)\n",
    "# - entry: object type causes input type problem for the model (bring it back in by one-hot encoding or label encoding if necessary)\n",
    "# - y_ligand: y value, not necessary for input\n",
    "df_x = df.drop(['annotation_sequence', 'annotation_atomrec', 'entry', 'y_Ligand'], axis=1)\n",
    "\n",
    "# convert boolean columns into integer\n",
    "df_x[df_x.select_dtypes(include='bool').columns] = df_x.select_dtypes(include='bool').astype(int)\n",
    "\n",
    "# scale data\n",
    "\n",
    "df_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "929500a5-3116-4fe4-ac6c-17fb6a8d8257",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(df_x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "579eac48-5cf8-4a92-8b5a-412db08f72db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27070507, -0.14566151, -0.23303469, ..., -0.8361749 ,\n",
       "        -0.22705362, -0.73775641],\n",
       "       [-0.27070507, -0.14566151, -0.23303469, ...,  0.88727423,\n",
       "        -0.61391211, -0.760345  ],\n",
       "       [-0.27070507, -0.14566151,  4.29120657, ...,  0.66333826,\n",
       "         0.34683465, -0.5058469 ],\n",
       "       ...,\n",
       "       [-0.27070507, -0.14566151, -0.23303469, ...,  1.66070372,\n",
       "         2.04297665,  0.28174189],\n",
       "       [-0.27070507, -0.14566151,  4.29120657, ..., -0.53290914,\n",
       "         0.00479124, -0.52391777],\n",
       "       [ 3.69405717, -0.14566151, -0.23303469, ..., -1.37631564,\n",
       "         0.25506508, -0.31158504]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling\n",
    "numeric_cols = x_train.select_dtypes(include=[float, int]).columns\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train[numeric_cols])\n",
    "x_val_scaled = scaler.fit_transform(x_val[numeric_cols])\n",
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63551bfd-f816-4e8f-a0f2-b942943f10ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## For model training & hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc354609-23b7-49e8-a8cb-34e29557b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train model (create, compile, and fit with validation dataset)\n",
    "def train(model, x, y, x_val, y_val, lr, epochs, batchsz):\n",
    "    log_dir = \"logs/\" + model.name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    print (\"MODEL NAME:\", model.name)\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model.fit(\n",
    "        x, \n",
    "        y,\n",
    "        epochs=epochs,\n",
    "        batch_size=batchsz,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[tensorboard_callback],\n",
    "        verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65f76bb1-b318-4540-8bc1-a8dfe951dd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 66476), started 2 days, 3:32:17 ago. (Use '!kill 66476' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-201e1f97f684df17\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-201e1f97f684df17\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72176477-ae2b-45a8-9852-1e4647675556",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 1: simple NN with 3 layers \n",
    "Accuracy: 96.62%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eb9ef05-fca2-4628-b9d0-2e60db3cbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define keras model\n",
    "model1 = Sequential([\n",
    "    Dense(12, input_dim=x_train.shape[1], activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af68d83b-45db-44d9-b744-3c7c18e9b931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL NAME: sequential\n",
      "Epoch 1/50\n",
      "7458/7458 [==============================] - 15s 1ms/step - loss: 0.1402 - accuracy: 0.9643 - val_loss: 0.1322 - val_accuracy: 0.9650\n",
      "Epoch 2/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1293 - accuracy: 0.9654 - val_loss: 0.1294 - val_accuracy: 0.9651\n",
      "Epoch 3/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1270 - accuracy: 0.9655 - val_loss: 0.1275 - val_accuracy: 0.9651\n",
      "Epoch 4/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1252 - accuracy: 0.9658 - val_loss: 0.1255 - val_accuracy: 0.9656\n",
      "Epoch 5/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1240 - accuracy: 0.9659 - val_loss: 0.1255 - val_accuracy: 0.9657\n",
      "Epoch 6/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1233 - accuracy: 0.9660 - val_loss: 0.1244 - val_accuracy: 0.9659\n",
      "Epoch 7/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1226 - accuracy: 0.9661 - val_loss: 0.1236 - val_accuracy: 0.9657\n",
      "Epoch 8/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1222 - accuracy: 0.9662 - val_loss: 0.1232 - val_accuracy: 0.9658\n",
      "Epoch 9/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1219 - accuracy: 0.9661 - val_loss: 0.1232 - val_accuracy: 0.9658\n",
      "Epoch 10/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1216 - accuracy: 0.9662 - val_loss: 0.1229 - val_accuracy: 0.9657\n",
      "Epoch 11/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1213 - accuracy: 0.9662 - val_loss: 0.1230 - val_accuracy: 0.9656\n",
      "Epoch 12/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1210 - accuracy: 0.9662 - val_loss: 0.1224 - val_accuracy: 0.9659\n",
      "Epoch 13/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1207 - accuracy: 0.9661 - val_loss: 0.1223 - val_accuracy: 0.9659\n",
      "Epoch 14/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1205 - accuracy: 0.9664 - val_loss: 0.1220 - val_accuracy: 0.9659\n",
      "Epoch 15/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1202 - accuracy: 0.9662 - val_loss: 0.1216 - val_accuracy: 0.9660\n",
      "Epoch 16/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1200 - accuracy: 0.9663 - val_loss: 0.1222 - val_accuracy: 0.9659\n",
      "Epoch 17/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1197 - accuracy: 0.9663 - val_loss: 0.1214 - val_accuracy: 0.9659\n",
      "Epoch 18/50\n",
      "7458/7458 [==============================] - 14s 2ms/step - loss: 0.1196 - accuracy: 0.9664 - val_loss: 0.1213 - val_accuracy: 0.9660\n",
      "Epoch 19/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1195 - accuracy: 0.9663 - val_loss: 0.1214 - val_accuracy: 0.9659\n",
      "Epoch 20/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1192 - accuracy: 0.9664 - val_loss: 0.1210 - val_accuracy: 0.9660\n",
      "Epoch 21/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1192 - accuracy: 0.9664 - val_loss: 0.1205 - val_accuracy: 0.9661\n",
      "Epoch 22/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1190 - accuracy: 0.9665 - val_loss: 0.1213 - val_accuracy: 0.9660\n",
      "Epoch 23/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1188 - accuracy: 0.9665 - val_loss: 0.1206 - val_accuracy: 0.9659\n",
      "Epoch 24/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1187 - accuracy: 0.9663 - val_loss: 0.1208 - val_accuracy: 0.9661\n",
      "Epoch 25/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1186 - accuracy: 0.9665 - val_loss: 0.1206 - val_accuracy: 0.9662\n",
      "Epoch 26/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1184 - accuracy: 0.9665 - val_loss: 0.1203 - val_accuracy: 0.9662\n",
      "Epoch 27/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1183 - accuracy: 0.9666 - val_loss: 0.1205 - val_accuracy: 0.9663\n",
      "Epoch 28/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1183 - accuracy: 0.9666 - val_loss: 0.1204 - val_accuracy: 0.9662\n",
      "Epoch 29/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1181 - accuracy: 0.9666 - val_loss: 0.1199 - val_accuracy: 0.9663\n",
      "Epoch 30/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1180 - accuracy: 0.9667 - val_loss: 0.1205 - val_accuracy: 0.9661\n",
      "Epoch 31/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1180 - accuracy: 0.9667 - val_loss: 0.1201 - val_accuracy: 0.9662\n",
      "Epoch 32/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1179 - accuracy: 0.9666 - val_loss: 0.1202 - val_accuracy: 0.9665\n",
      "Epoch 33/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1178 - accuracy: 0.9668 - val_loss: 0.1200 - val_accuracy: 0.9663\n",
      "Epoch 34/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1178 - accuracy: 0.9667 - val_loss: 0.1197 - val_accuracy: 0.9664\n",
      "Epoch 35/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1177 - accuracy: 0.9666 - val_loss: 0.1199 - val_accuracy: 0.9664\n",
      "Epoch 36/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1177 - accuracy: 0.9667 - val_loss: 0.1196 - val_accuracy: 0.9665\n",
      "Epoch 37/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1174 - accuracy: 0.9668 - val_loss: 0.1195 - val_accuracy: 0.9665\n",
      "Epoch 38/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1175 - accuracy: 0.9667 - val_loss: 0.1199 - val_accuracy: 0.9664\n",
      "Epoch 39/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1173 - accuracy: 0.9668 - val_loss: 0.1198 - val_accuracy: 0.9664\n",
      "Epoch 40/50\n",
      "7458/7458 [==============================] - 10s 1ms/step - loss: 0.1173 - accuracy: 0.9667 - val_loss: 0.1197 - val_accuracy: 0.9664\n",
      "Epoch 41/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1174 - accuracy: 0.9667 - val_loss: 0.1196 - val_accuracy: 0.9664\n",
      "Epoch 42/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1172 - accuracy: 0.9667 - val_loss: 0.1196 - val_accuracy: 0.9665\n",
      "Epoch 43/50\n",
      "7458/7458 [==============================] - 12s 2ms/step - loss: 0.1172 - accuracy: 0.9668 - val_loss: 0.1196 - val_accuracy: 0.9664\n",
      "Epoch 44/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1171 - accuracy: 0.9668 - val_loss: 0.1193 - val_accuracy: 0.9666\n",
      "Epoch 45/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1170 - accuracy: 0.9668 - val_loss: 0.1196 - val_accuracy: 0.9664\n",
      "Epoch 46/50\n",
      "7458/7458 [==============================] - 11s 2ms/step - loss: 0.1170 - accuracy: 0.9668 - val_loss: 0.1196 - val_accuracy: 0.9663\n",
      "Epoch 47/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1170 - accuracy: 0.9667 - val_loss: 0.1193 - val_accuracy: 0.9664\n",
      "Epoch 48/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1169 - accuracy: 0.9668 - val_loss: 0.1194 - val_accuracy: 0.9664\n",
      "Epoch 49/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1169 - accuracy: 0.9668 - val_loss: 0.1205 - val_accuracy: 0.9663\n",
      "Epoch 50/50\n",
      "7458/7458 [==============================] - 11s 1ms/step - loss: 0.1169 - accuracy: 0.9668 - val_loss: 0.1196 - val_accuracy: 0.9663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c01bda050>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model1, x_train_scaled, y_train, x_val_scaled, y_val, lr=0.001, epochs=50, batchsz=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "452656de-6bb2-4580-b89b-e616c40c1280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3885/3885 [==============================] - 4s 982us/step - loss: 0.1196 - accuracy: 0.9663\n",
      "Accuracy: 96.63\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "_, accuracy = model1.evaluate(x_val_scaled, y_val)\n",
    "print('Accuracy: %.2f' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac4cc9-2338-433b-be1c-4ef67705b580",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Experimenting with learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4784099a-c2e0-4ed3-96f6-64503269d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lr(model, step_size, num_steps, annealing_ratio, lr): \n",
    "    log_dir = \"logs/\" + model.name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    print (\"MODEL NAME:\", model.name)\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(\n",
    "          optimizer=optimizer,\n",
    "          loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "          metrics=[\"accuracy\"],\n",
    "    )\n",
    "    for step in range(num_steps): \n",
    "        print('step:', step)\n",
    "        if step > 0:\n",
    "          lr = lr * annealing_ratio\n",
    "        model.fit(\n",
    "            x_train, \n",
    "            y_train,\n",
    "            epochs=step_size,\n",
    "            validation_data=(x_val, y_val),\n",
    "            callbacks=[tensorboard_callback],\n",
    "        verbose=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed823113-9567-47a6-975b-cf8ad5c805f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL NAME: sequential_1\n",
      "Epoch 1/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1515 - accuracy: 0.9653 - val_loss: 0.1531 - val_accuracy: 0.9652\n",
      "Epoch 2/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1513 - val_accuracy: 0.9652\n",
      "Epoch 3/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1510 - val_accuracy: 0.9652\n",
      "Epoch 4/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1531 - val_accuracy: 0.9652\n",
      "Epoch 5/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1515 - val_accuracy: 0.9652\n",
      "Epoch 1/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1512 - val_accuracy: 0.9652\n",
      "Epoch 2/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1523 - val_accuracy: 0.9652\n",
      "Epoch 3/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1515 - accuracy: 0.9653 - val_loss: 0.1513 - val_accuracy: 0.9652\n",
      "Epoch 4/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1511 - val_accuracy: 0.9652\n",
      "Epoch 5/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1523 - val_accuracy: 0.9652\n",
      "Epoch 1/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1515 - accuracy: 0.9653 - val_loss: 0.1511 - val_accuracy: 0.9652\n",
      "Epoch 2/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1516 - val_accuracy: 0.9652\n",
      "Epoch 3/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1513 - accuracy: 0.9653 - val_loss: 0.1521 - val_accuracy: 0.9652\n",
      "Epoch 4/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1515 - accuracy: 0.9653 - val_loss: 0.1510 - val_accuracy: 0.9652\n",
      "Epoch 5/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1511 - val_accuracy: 0.9652\n",
      "Epoch 1/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1513 - accuracy: 0.9653 - val_loss: 0.1511 - val_accuracy: 0.9652\n",
      "Epoch 2/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1514 - val_accuracy: 0.9652\n",
      "Epoch 3/5\n",
      "11653/11653 [==============================] - 18s 2ms/step - loss: 0.1513 - accuracy: 0.9653 - val_loss: 0.1543 - val_accuracy: 0.9652\n",
      "Epoch 4/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1525 - val_accuracy: 0.9652\n",
      "Epoch 5/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1511 - val_accuracy: 0.9652\n",
      "Epoch 1/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1515 - val_accuracy: 0.9652\n",
      "Epoch 2/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1524 - val_accuracy: 0.9652\n",
      "Epoch 3/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1531 - val_accuracy: 0.9652\n",
      "Epoch 4/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1522 - val_accuracy: 0.9652\n",
      "Epoch 5/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1513 - accuracy: 0.9653 - val_loss: 0.1511 - val_accuracy: 0.9652\n",
      "Epoch 1/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1511 - val_accuracy: 0.9652\n",
      "Epoch 2/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1541 - val_accuracy: 0.9652\n",
      "Epoch 3/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1526 - val_accuracy: 0.9652\n",
      "Epoch 4/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1512 - val_accuracy: 0.9652\n",
      "Epoch 5/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1520 - val_accuracy: 0.9652\n",
      "Epoch 1/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1523 - val_accuracy: 0.9652\n",
      "Epoch 2/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1517 - val_accuracy: 0.9652\n",
      "Epoch 3/5\n",
      "11653/11653 [==============================] - 18s 2ms/step - loss: 0.1515 - accuracy: 0.9653 - val_loss: 0.1510 - val_accuracy: 0.9652\n",
      "Epoch 4/5\n",
      "11653/11653 [==============================] - 23s 2ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1511 - val_accuracy: 0.9652\n",
      "Epoch 5/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1521 - val_accuracy: 0.9652\n",
      "Epoch 1/5\n",
      "11653/11653 [==============================] - 18s 2ms/step - loss: 0.1515 - accuracy: 0.9653 - val_loss: 0.1516 - val_accuracy: 0.9652\n",
      "Epoch 2/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1515 - accuracy: 0.9653 - val_loss: 0.1515 - val_accuracy: 0.9652\n",
      "Epoch 3/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1522 - val_accuracy: 0.9652\n",
      "Epoch 4/5\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1515 - accuracy: 0.9653 - val_loss: 0.1510 - val_accuracy: 0.9652\n",
      "Epoch 5/5\n",
      "11653/11653 [==============================] - 17s 1ms/step - loss: 0.1514 - accuracy: 0.9653 - val_loss: 0.1541 - val_accuracy: 0.9652\n"
     ]
    }
   ],
   "source": [
    "model1_lrtuned = model1\n",
    "tune_lr(model1_lrtuned, 5, 8, 0.5, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a994c0-4da8-47b2-8d31-b24eda2141df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Grid search -- need to customize for this dataset\n",
    "Using hparams dashboard (preview)\n",
    "\n",
    "Source: https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c726f6cc-915e-4cdd-9c89-2cd4cbf63845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "LEARNING_RATE = hp.HParam('learning_rate', hp.RealInterval(0.001, 0.01))\n",
    "# HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([16, 32, 64]))\n",
    "NUM_LAYERS = hp.HParam('num_layers', hp.IntInterval(1, 3))\n",
    "NUM_UNITS = hp.HParam('num_units', hp.Discrete([8, 12, 16]))\n",
    "NUM_EPOCHS = hp.HParam('num_epochs', hp.Discrete([10, 20, 30]))\n",
    "\n",
    "# configuration on TensorBoard\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[LEARNING_RATE, NUM_LAYERS, NUM_UNITS, NUM_EPOCHS],\n",
    "        metrics=[hp.Metric('accuracy', display_name='Accuracy')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aae2d68e-89c9-4cd4-aa1f-3104d19451ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log hyperparameters and metrics while training\n",
    "def train_test_model(x, y, x_val, y_val, hparams):\n",
    "    # create model\n",
    "    model = Sequential([\n",
    "        Dense(hparams['NUM_UNITS'], input_dim=x_train.shape[1], activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Set up logging:\n",
    "    print ('MODEL NAME:', model.name)\n",
    "    log_dir = \"hparam_logs/\" + model.name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "        hp.KerasCallback(log_dir, hparams),\n",
    "    ]\n",
    "    \n",
    "    #Prepare our model:\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=hparams['LEARNING_RATE'])\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    #Train:\n",
    "    return model.fit(\n",
    "        x, \n",
    "        y, \n",
    "        epochs=hparams['NUM_EPOCHS'],\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    _, accuracy = model.evaluate(x_val, y_val)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7820d712-8e65-421c-b20d-539c5b8f231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "Current parameters: {'NUM_LAYERS': 1, 'NUM_UNITS': 8, 'NUM_EPOCHS': 10, 'LEARNING_RATE': 0.001}\n",
      "MODEL NAME: sequential_3\n",
      "Epoch 1/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1932 - accuracy: 0.9616\n",
      "Epoch 2/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1350 - accuracy: 0.9653\n",
      "Epoch 3/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1298 - accuracy: 0.9654\n",
      "Epoch 4/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1285 - accuracy: 0.9654\n",
      "Epoch 5/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1269 - accuracy: 0.9654\n",
      "Epoch 6/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1259 - accuracy: 0.9654\n",
      "Epoch 7/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1253 - accuracy: 0.9654\n",
      "Epoch 8/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1248 - accuracy: 0.9654\n",
      "Epoch 9/10\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1244 - accuracy: 0.9654\n",
      "Epoch 10/10\n",
      "11653/11653 [==============================] - 15s 1ms/step - loss: 0.1242 - accuracy: 0.9655\n",
      "--- Starting trial: run-0\n",
      "Current parameters: {'NUM_LAYERS': 1, 'NUM_UNITS': 8, 'NUM_EPOCHS': 10, 'LEARNING_RATE': 0.01}\n",
      "MODEL NAME: sequential_4\n",
      "Epoch 1/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1475 - accuracy: 0.9651\n",
      "Epoch 2/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1400 - accuracy: 0.9654\n",
      "Epoch 3/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1386 - accuracy: 0.9654\n",
      "Epoch 4/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1388 - accuracy: 0.9654\n",
      "Epoch 5/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1376 - accuracy: 0.9654\n",
      "Epoch 6/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1367 - accuracy: 0.9654\n",
      "Epoch 7/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1361 - accuracy: 0.9654\n",
      "Epoch 8/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1361 - accuracy: 0.9654\n",
      "Epoch 9/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1358 - accuracy: 0.9654\n",
      "Epoch 10/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1357 - accuracy: 0.9654\n",
      "--- Starting trial: run-0\n",
      "Current parameters: {'NUM_LAYERS': 1, 'NUM_UNITS': 8, 'NUM_EPOCHS': 20, 'LEARNING_RATE': 0.001}\n",
      "MODEL NAME: sequential_5\n",
      "Epoch 1/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.5316 - accuracy: 0.9532\n",
      "Epoch 2/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1367 - accuracy: 0.9654\n",
      "Epoch 3/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1348 - accuracy: 0.9654\n",
      "Epoch 4/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1329 - accuracy: 0.9654\n",
      "Epoch 5/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1306 - accuracy: 0.9654\n",
      "Epoch 6/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1287 - accuracy: 0.9654\n",
      "Epoch 7/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1276 - accuracy: 0.9654\n",
      "Epoch 8/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1271 - accuracy: 0.9654\n",
      "Epoch 9/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1267 - accuracy: 0.9654\n",
      "Epoch 10/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1264 - accuracy: 0.9654\n",
      "Epoch 11/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1261 - accuracy: 0.9654\n",
      "Epoch 12/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1259 - accuracy: 0.9654\n",
      "Epoch 13/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1260 - accuracy: 0.9654\n",
      "Epoch 14/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1258 - accuracy: 0.9654\n",
      "Epoch 15/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1258 - accuracy: 0.9654\n",
      "Epoch 16/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1256 - accuracy: 0.9654\n",
      "Epoch 17/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1256 - accuracy: 0.9654\n",
      "Epoch 18/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1254 - accuracy: 0.9654\n",
      "Epoch 19/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1254 - accuracy: 0.9654\n",
      "Epoch 20/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1398 - accuracy: 0.9654\n",
      "Epoch 18/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1386 - accuracy: 0.9654\n",
      "Epoch 19/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1377 - accuracy: 0.9654\n",
      "Epoch 20/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1369 - accuracy: 0.9654\n",
      "--- Starting trial: run-0\n",
      "Current parameters: {'NUM_LAYERS': 1, 'NUM_UNITS': 8, 'NUM_EPOCHS': 30, 'LEARNING_RATE': 0.001}\n",
      "MODEL NAME: sequential_7\n",
      "Epoch 1/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1624 - accuracy: 0.9634\n",
      "Epoch 2/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1369 - accuracy: 0.9653\n",
      "Epoch 3/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1316 - accuracy: 0.9654\n",
      "Epoch 4/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1302 - accuracy: 0.9654\n",
      "Epoch 5/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1294 - accuracy: 0.9654\n",
      "Epoch 6/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1216 - accuracy: 0.9654\n",
      "Epoch 25/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1217 - accuracy: 0.9654\n",
      "Epoch 26/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1215 - accuracy: 0.9654\n",
      "Epoch 27/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1215 - accuracy: 0.9655\n",
      "Epoch 28/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1215 - accuracy: 0.9654\n",
      "Epoch 29/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1213 - accuracy: 0.9654\n",
      "Epoch 30/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1214 - accuracy: 0.9654\n",
      "--- Starting trial: run-0\n",
      "Current parameters: {'NUM_LAYERS': 1, 'NUM_UNITS': 8, 'NUM_EPOCHS': 30, 'LEARNING_RATE': 0.01}\n",
      "MODEL NAME: sequential_8\n",
      "Epoch 1/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1947 - accuracy: 0.9643\n",
      "Epoch 2/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1436 - accuracy: 0.9654\n",
      "Epoch 3/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1364 - accuracy: 0.9654\n",
      "Epoch 16/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1374 - accuracy: 0.9654\n",
      "Epoch 17/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1385 - accuracy: 0.9654\n",
      "Epoch 18/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1364 - accuracy: 0.9654\n",
      "Epoch 19/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1364 - accuracy: 0.9654\n",
      "Epoch 20/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1368 - accuracy: 0.9654\n",
      "Epoch 21/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1380 - accuracy: 0.9654\n",
      "Epoch 22/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1362 - accuracy: 0.9654\n",
      "Epoch 23/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1363 - accuracy: 0.9654\n",
      "Epoch 24/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1362 - accuracy: 0.9654\n",
      "Epoch 25/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1360 - accuracy: 0.9654\n",
      "Epoch 26/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1358 - accuracy: 0.9654\n",
      "Epoch 27/30\n",
      "11653/11653 [==============================] - 15s 1ms/step - loss: 0.1256 - accuracy: 0.9654\n",
      "Epoch 6/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1246 - accuracy: 0.9654\n",
      "Epoch 7/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1241 - accuracy: 0.9654\n",
      "Epoch 8/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1238 - accuracy: 0.9654\n",
      "Epoch 9/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1364 - accuracy: 0.9654\n",
      "Epoch 9/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1364 - accuracy: 0.9654\n",
      "Epoch 10/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1359 - accuracy: 0.9654\n",
      "--- Starting trial: run-0\n",
      "Current parameters: {'NUM_LAYERS': 1, 'NUM_UNITS': 12, 'NUM_EPOCHS': 20, 'LEARNING_RATE': 0.001}\n",
      "MODEL NAME: sequential_11\n",
      "Epoch 1/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1741 - accuracy: 0.9637\n",
      "Epoch 2/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1355 - accuracy: 0.9653\n",
      "Epoch 3/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1279 - accuracy: 0.9654\n",
      "Epoch 4/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1257 - accuracy: 0.9654\n",
      "Epoch 5/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1250 - accuracy: 0.9654\n",
      "Epoch 6/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1246 - accuracy: 0.9654\n",
      "Epoch 7/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1242 - accuracy: 0.9654\n",
      "Epoch 8/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1241 - accuracy: 0.9654\n",
      "Epoch 9/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1235 - accuracy: 0.9655\n",
      "Epoch 10/20\n",
      "  632/11653 [>.............................] - ETA: 12s - loss: 0.1260 - accuracy: 0.9643"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1990 - accuracy: 0.9646\n",
      "Epoch 2/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1375 - accuracy: 0.9654\n",
      "Epoch 3/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1361 - accuracy: 0.9654\n",
      "Epoch 4/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1366 - accuracy: 0.9654\n",
      "Epoch 5/20\n",
      "11653/11653 [==============================] - 15s 1ms/step - loss: 0.1357 - accuracy: 0.9654\n",
      "Epoch 6/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1351 - accuracy: 0.9654\n",
      "Epoch 7/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1345 - accuracy: 0.9654\n",
      "Epoch 8/20\n",
      "11653/11653 [==============================] - 15s 1ms/step - loss: 0.1345 - accuracy: 0.9654\n",
      "Epoch 9/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1343 - accuracy: 0.9654\n",
      "Epoch 10/20\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1333 - accuracy: 0.9654\n",
      "Epoch 11/20\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1311 - accuracy: 0.9654\n",
      "Epoch 12/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1306 - accuracy: 0.9654\n",
      "Epoch 13/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1303 - accuracy: 0.9654\n",
      "Epoch 14/20\n",
      "11653/11653 [==============================] - 15s 1ms/step - loss: 0.1304 - accuracy: 0.9654\n",
      "Epoch 15/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1303 - accuracy: 0.9654\n",
      "Epoch 16/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1305 - accuracy: 0.9654\n",
      "Epoch 17/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1305 - accuracy: 0.9654\n",
      "Epoch 18/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1303 - accuracy: 0.9654\n",
      "Epoch 19/20\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1303 - accuracy: 0.9654\n",
      "Epoch 20/20\n",
      "11653/11653 [==============================] - 16s 1ms/step - loss: 0.1303 - accuracy: 0.9654\n",
      "--- Starting trial: run-0\n",
      "Current parameters: {'NUM_LAYERS': 1, 'NUM_UNITS': 12, 'NUM_EPOCHS': 30, 'LEARNING_RATE': 0.001}\n",
      "MODEL NAME: sequential_13\n",
      "Epoch 1/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.2852 - accuracy: 0.9599\n",
      "Epoch 2/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1466 - accuracy: 0.9649\n",
      "Epoch 3/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1356 - accuracy: 0.9653\n",
      "Epoch 4/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1294 - accuracy: 0.9654\n",
      "Epoch 5/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1262 - accuracy: 0.9655\n",
      "Epoch 6/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1244 - accuracy: 0.9655\n",
      "Epoch 7/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1238 - accuracy: 0.9655\n",
      "Epoch 8/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1234 - accuracy: 0.9656\n",
      "Epoch 9/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1232 - accuracy: 0.9656\n",
      "Epoch 10/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1227 - accuracy: 0.9657\n",
      "Epoch 11/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1225 - accuracy: 0.9657\n",
      "Epoch 12/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1224 - accuracy: 0.9657\n",
      "Epoch 13/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1223 - accuracy: 0.9657\n",
      "Epoch 14/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1222 - accuracy: 0.9657\n",
      "Epoch 15/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1220 - accuracy: 0.9657\n",
      "Epoch 16/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1218 - accuracy: 0.9658\n",
      "Epoch 17/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1218 - accuracy: 0.9657\n",
      "Epoch 18/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1216 - accuracy: 0.9657\n",
      "Epoch 19/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1216 - accuracy: 0.9657\n",
      "Epoch 20/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1215 - accuracy: 0.9658\n",
      "Epoch 21/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1214 - accuracy: 0.9658\n",
      "Epoch 22/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1212 - accuracy: 0.9658\n",
      "Epoch 23/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1212 - accuracy: 0.9658\n",
      "Epoch 24/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1210 - accuracy: 0.9658\n",
      "Epoch 25/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1211 - accuracy: 0.9657\n",
      "Epoch 26/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1210 - accuracy: 0.9658\n",
      "Epoch 27/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1210 - accuracy: 0.9658\n",
      "Epoch 28/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1211 - accuracy: 0.9658\n",
      "Epoch 29/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1209 - accuracy: 0.9658\n",
      "Epoch 30/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1210 - accuracy: 0.9658\n",
      "--- Starting trial: run-0\n",
      "Current parameters: {'NUM_LAYERS': 1, 'NUM_UNITS': 12, 'NUM_EPOCHS': 30, 'LEARNING_RATE': 0.01}\n",
      "MODEL NAME: sequential_14\n",
      "Epoch 1/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1471 - accuracy: 0.9650\n",
      "Epoch 2/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1406 - accuracy: 0.9654\n",
      "Epoch 3/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1378 - accuracy: 0.9654\n",
      "Epoch 4/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1360 - accuracy: 0.9654\n",
      "Epoch 5/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1352 - accuracy: 0.9654\n",
      "Epoch 6/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1350 - accuracy: 0.9654\n",
      "Epoch 7/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1349 - accuracy: 0.9654\n",
      "Epoch 8/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1363 - accuracy: 0.9654\n",
      "Epoch 9/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1350 - accuracy: 0.9654\n",
      "Epoch 10/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1346 - accuracy: 0.9654\n",
      "Epoch 11/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1360 - accuracy: 0.9654\n",
      "Epoch 12/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1370 - accuracy: 0.9654\n",
      "Epoch 13/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1348 - accuracy: 0.9654\n",
      "Epoch 14/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1394 - accuracy: 0.9654\n",
      "Epoch 15/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1342 - accuracy: 0.9654\n",
      "Epoch 16/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1353 - accuracy: 0.9654\n",
      "Epoch 17/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1351 - accuracy: 0.9654\n",
      "Epoch 18/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1349 - accuracy: 0.9654\n",
      "Epoch 19/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1359 - accuracy: 0.9654\n",
      "Epoch 20/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1352 - accuracy: 0.9654\n",
      "Epoch 21/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1353 - accuracy: 0.9654\n",
      "Epoch 22/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1347 - accuracy: 0.9654\n",
      "Epoch 23/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1364 - accuracy: 0.9654\n",
      "Epoch 24/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1364 - accuracy: 0.9654\n",
      "Epoch 25/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1515 - accuracy: 0.9651\n",
      "Epoch 2/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1403 - accuracy: 0.9654\n",
      "Epoch 3/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1390 - accuracy: 0.9654\n",
      "Epoch 4/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1374 - accuracy: 0.9654\n",
      "Epoch 5/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1363 - accuracy: 0.9654\n",
      "Epoch 6/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1360 - accuracy: 0.9654\n",
      "Epoch 7/10\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1358 - accuracy: 0.9654\n",
      "Epoch 8/10\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1667 - accuracy: 0.9651\n",
      "Epoch 2/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1345 - accuracy: 0.9654\n",
      "Epoch 9/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1343 - accuracy: 0.9654\n",
      "Epoch 10/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1343 - accuracy: 0.9654\n",
      "Epoch 11/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1342 - accuracy: 0.9654\n",
      "Epoch 12/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1343 - accuracy: 0.9654\n",
      "Epoch 13/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1340 - accuracy: 0.9654\n",
      "Epoch 14/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1344 - accuracy: 0.9654\n",
      "Epoch 15/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1342 - accuracy: 0.9654\n",
      "Epoch 16/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1340 - accuracy: 0.9654\n",
      "Epoch 17/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1341 - accuracy: 0.9654\n",
      "Epoch 18/20\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1338 - accuracy: 0.9654\n",
      "Epoch 19/20\n",
      "10023/11653 [========================>.....] - ETA: 1s - loss: 0.1345 - accuracy: 0.9652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.2252 - accuracy: 0.9606\n",
      "Epoch 2/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1444 - accuracy: 0.9650\n",
      "Epoch 3/30\n",
      "11653/11653 [==============================] - 14s 1ms/step - loss: 0.1207 - accuracy: 0.9657\n",
      "Epoch 26/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1207 - accuracy: 0.9656\n",
      "Epoch 27/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1205 - accuracy: 0.9657\n",
      "Epoch 28/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1205 - accuracy: 0.9656\n",
      "Epoch 29/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1205 - accuracy: 0.9656\n",
      "Epoch 30/30\n",
      "11653/11653 [==============================] - 13s 1ms/step - loss: 0.1203 - accuracy: 0.9657\n",
      "--- Starting trial: run-0\n",
      "Current parameters: {'NUM_LAYERS': 1, 'NUM_UNITS': 16, 'NUM_EPOCHS': 30, 'LEARNING_RATE': 0.01}\n",
      "MODEL NAME: sequential_20\n",
      "Epoch 1/30\n",
      " 8675/11653 [=====================>........] - ETA: 3s - loss: 0.1536 - accuracy: 0.9649"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--- Starting trial: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m run_name)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent parameters:\u001b[39m\u001b[38;5;124m'\u001b[39m, hparams)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mtrain_test_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[52], line 27\u001b[0m, in \u001b[0;36mtrain_test_model\u001b[1;34m(x, y, x_val, y_val, hparams)\u001b[0m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     21\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     22\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(),\n\u001b[0;32m     23\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#Train:\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNUM_EPOCHS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m _, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_val, y_val)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cxc\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cxc\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cxc\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cxc\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cxc\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cxc\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cxc\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cxc\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cxc\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_layers in (HP_NUM_LAYERS.domain.min_value, HP_NUM_LAYERS.domain.max_value):\n",
    "    for num_units in HP_NUM_UNITS.domain.values:\n",
    "        for num_epochs in HP_NUM_EPOCHS.domain.values:\n",
    "            for learning_rate in (HP_LEARNING_RATE.domain.min_value, HP_LEARNING_RATE.domain.max_value):\n",
    "                hparams = {\n",
    "                    'NUM_LAYERS': num_layers,\n",
    "                    'NUM_UNITS': num_units,\n",
    "                    'NUM_EPOCHS': num_epochs,\n",
    "                    'LEARNING_RATE': learning_rate\n",
    "                }\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('--- Starting trial: %s' % run_name)\n",
    "                print('Current parameters:', hparams)\n",
    "                train_test_model(x_train, y_train, x_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b861a-7b90-476d-932f-67d8d99c6391",
   "metadata": {},
   "source": [
    "## Random search\n",
    "https://stackoverflow.com/questions/40467296/tensorflow-how-to-implement-hyper-parameters-random-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c21cf87-6116-4c76-bda6-ebd59bfae7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_hyperparams(lr_min, lr_max, kp_min, kp_max):\n",
    "    '''generate random learning rate and keep probability'''\n",
    "    # random search through log space for learning rate\n",
    "    random_learng_rate = 10**np.random.uniform(lr_min, lr_max)\n",
    "    random_keep_prob = np.random.uniform(kp_min, kp_max)\n",
    "    return random_learning_rate, random_keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ffc4db-e55c-4523-9b6d-28279109bfbd",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec281b2-ffbb-4b87-add3-91d06c2b38ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
